#!/usr/bin/python

"""

"""

import os
import geopandas as gpd
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from shapely.geometry import Point
from scipy.stats import linregress

# --------------------------
# 1. Set Paths and Load the Shapefiles
# --------------------------
# Define the base folder for the samples
base_folder = r"C:\Users\ibana\Desktop\JRC_Tanganica\GIS_Intermediate\Intermediate_files\SWOT\0_Samples"
input_shapefile = os.path.join(base_folder, "Samples_with_RasterValues.shp")

# Load the point shapefile with water elevation data
gdf = gpd.read_file(input_shapefile)

# Load the lake boundary shapefile from the provided location
lake_boundary_shapefile = r"C:\Users\ibana\Desktop\deleteme\Lake\tang.shp"
lake_gdf = gpd.read_file(lake_boundary_shapefile)

# Create a single geometry for the lake boundary by unioning all parts (using the recommended method)
lake_boundary = lake_gdf.geometry.union_all()
# Precompute the boundary edge
lake_boundary_edge = lake_boundary.boundary

# Identify elevation columns (assuming they start with 'd')
elevation_cols = [col for col in gdf.columns if col.startswith('d')]

# --------------------------
# 2. Define Spatial Regions using the Provided Lake Boundary
# --------------------------
# Calculate distance from each point to the lake boundary's edge using the precomputed boundary
gdf["dist_to_boundary"] = gdf.geometry.apply(lambda geom: geom.distance(lake_boundary_edge))

# Define a threshold (10% of max distance) to classify points as 'coastal'
threshold = 0.1 * gdf["dist_to_boundary"].max()
gdf["region_coastal"] = gdf["dist_to_boundary"].apply(lambda d: 'coastal' if d < threshold else 'central')

# For north vs. south: use the y-coordinate (latitude) and the median value
gdf["lat"] = gdf.geometry.apply(lambda geom: geom.y)
median_lat = gdf["lat"].median()
gdf["region_ns"] = gdf["lat"].apply(lambda lat: 'north' if lat > median_lat else 'south')


# --------------------------
# 2.1. Write the updated GeoDataFrame to a new shapefile
# --------------------------

output_shapefile = os.path.join(base_folder, "Samples_with_Distance_and_Region.shp")
gdf.to_file(output_shapefile)

print("New shapefile with distance and region classifications saved as:", output_shapefile)

# --------------------------
# 3. Reshape Data for Temporal Analysis and Filter Out Invalid Values
# --------------------------
# Melt the data so that each row represents a point-date combination
df_long = gdf[['geometry', 'region_coastal', 'region_ns'] + elevation_cols].copy()
df_long = df_long.melt(id_vars=['geometry', 'region_coastal', 'region_ns'], 
                       value_vars=elevation_cols, 
                       var_name='date_str', 
                       value_name='elevation')

# Parse the date from the column name (e.g., 'd202411' -> November 2024)
df_long['year'] = df_long['date_str'].str[1:5].astype(int)
df_long['month'] = df_long['date_str'].str[5:7].astype(int)
df_long['date'] = pd.to_datetime(dict(year=df_long.year, month=df_long.month, day=1))

# Remove any elevation values equal to 0 (i.e., no valid data)
df_long = df_long[df_long['elevation'] != 0]

# --------------------------
# 4. Remove Outliers (IQR method applied per date)
# --------------------------
def remove_outliers(group):
    Q1 = group['elevation'].quantile(0.25)
    Q3 = group['elevation'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return group[(group['elevation'] >= lower_bound) & (group['elevation'] <= upper_bound)]

df_long = df_long.groupby('date', group_keys=False).apply(remove_outliers)

# --------------------------
# 5. Summary Statistics
# --------------------------
# Overall summary statistics by date
summary_overall = df_long.groupby('date')['elevation'].agg(['mean', 'median', 'std', 'min', 'max'])
summary_overall.to_csv(os.path.join(base_folder, "Summary_Statistics_Overall.csv"))
print("Overall Summary Statistics saved as 'Summary_Statistics_Overall.csv'")

# Summary statistics by coastal vs. central
summary_coastal = df_long.groupby(['date', 'region_coastal'])['elevation'].agg(['mean', 'median', 'std', 'min', 'max'])
summary_coastal.to_csv(os.path.join(base_folder, "Summary_Statistics_Coastal_vs_Central.csv"))
print("Coastal vs. Central Summary Statistics saved as 'Summary_Statistics_Coastal_vs_Central.csv'")

# Summary statistics by north vs. south
summary_ns = df_long.groupby(['date', 'region_ns'])['elevation'].agg(['mean', 'median', 'std', 'min', 'max'])
summary_ns.to_csv(os.path.join(base_folder, "Summary_Statistics_North_vs_South.csv"))
print("North vs. South Summary Statistics saved as 'Summary_Statistics_North_vs_South.csv'")

# --------------------------
# 6. Time Series Plots
# --------------------------
# Overall time series of average water elevation
plt.figure(figsize=(10, 5))
plt.plot(summary_overall.index, summary_overall['mean'], marker='o', label='Overall Mean')
plt.xlabel('Date')
plt.ylabel('Water Surface Elevation')
plt.title('Overall Average Water Surface Elevation Over Time')
plt.legend()
plt.grid(True)
overall_plot_path = os.path.join(base_folder, "Overall_TimeSeries.png")
plt.savefig(overall_plot_path)
plt.close()
print("Overall time series plot saved as 'Overall_TimeSeries.png'")

# Time series for coastal vs. central
fig, ax = plt.subplots(figsize=(10, 5))
for region in ['coastal', 'central']:
    region_data = summary_coastal.xs(region, level='region_coastal')
    ax.plot(region_data.index, region_data['mean'], marker='o', label=f'{region.capitalize()} Mean')
ax.set_xlabel('Date')
ax.set_ylabel('Water Surface Elevation')
ax.set_title('Water Surface Elevation Over Time (Coastal vs. Central)')
ax.legend()
ax.grid(True)
coastal_plot_path = os.path.join(base_folder, "Coastal_vs_Central_TimeSeries.png")
plt.savefig(coastal_plot_path)
plt.close()
print("Coastal vs. Central time series plot saved as 'Coastal_vs_Central_TimeSeries.png'")

# Time series for north vs. south
fig, ax = plt.subplots(figsize=(10, 5))
for region in ['north', 'south']:
    region_data = summary_ns.xs(region, level='region_ns')
    ax.plot(region_data.index, region_data['mean'], marker='o', label=f'{region.capitalize()} Mean')
ax.set_xlabel('Date')
ax.set_ylabel('Water Surface Elevation')
ax.set_title('Water Surface Elevation Over Time (North vs. South)')
ax.legend()
ax.grid(True)
ns_plot_path = os.path.join(base_folder, "North_vs_South_TimeSeries.png")
plt.savefig(ns_plot_path)
plt.close()
print("North vs. South time series plot saved as 'North_vs_South_TimeSeries.png'")

# --------------------------
# 7. Seasonal Boxplots
# --------------------------
df_long['month_name'] = df_long['date'].dt.strftime('%b')
plt.figure(figsize=(12, 6))
df_long.boxplot(column='elevation', by='month_name', grid=False)
plt.title('Monthly Distribution of Water Surface Elevation')
plt.suptitle('')  # remove default title to keep it clean
plt.xlabel('Month')
plt.ylabel('Elevation')
boxplot_path = os.path.join(base_folder, "Monthly_Boxplot.png")
plt.savefig(boxplot_path)
plt.close()
print("Monthly boxplot saved as 'Monthly_Boxplot.png'")

# --------------------------
# 8. Trend Analysis (Overall)
# --------------------------
# Convert dates to numeric format for regression (ordinal values)
time_numeric = summary_overall.index.map(pd.Timestamp.toordinal)
slope, intercept, r_value, p_value, std_err = linregress(time_numeric, summary_overall['mean'])
print(f"Trend Analysis Results: Slope: {slope:.4f}, Intercept: {intercept:.4f}, R-squared: {r_value**2:.4f}")

# Plot the overall trend
plt.figure(figsize=(10, 5))
plt.plot(summary_overall.index, summary_overall['mean'], marker='o', label='Overall Mean')
trend_line = intercept + slope * time_numeric
plt.plot(summary_overall.index, trend_line, color='red', linestyle='--', label='Trend Line')
plt.xlabel('Date')
plt.ylabel('Water Surface Elevation')
plt.title('Trend Analysis of Water Surface Elevation')
plt.legend()
plt.grid(True)
trend_plot_path = os.path.join(base_folder, "Trend_Analysis.png")
plt.savefig(trend_plot_path)
plt.close()
print("Trend analysis plot saved as 'Trend_Analysis.png'")

